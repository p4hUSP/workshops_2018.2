---
title: "Importação de dados"
author: "P4H"
output: html_document
---

<link rel="stylesheet" href="https://github.com/p4hUSP/workshops_2018.2/blob/master/imgs/css/style.css">

O que veremos hoje:

- [O que é programar? O que é um código de programação?](#intro)

- [Por que R?](#pqR)

- [Ciclo da Ciência de Dados.](#ciencia)

- [Eu vejo dados em todos os lugares!](#dados)
  
- [Como abrir arquivos TXT, CSV e Arquivos Delimitados?](#importar1)
  
- [Como abrir dados do Excel, SPSS e Stata?](#importar2)
  
- [Importar dados utilizando Webscraping.](#webscraping)
  
- [Salvando arquivos.](#salvar)

<a id='ciencia'></a>  

## Ciclo de Ciência de Dados

<img src="https://github.com/p4hUSP/workshops_2018.2/blob/master/imgs/w1_01.png" class="cienciadedados" class="center" class="center">

Assim como este é o nosso primeiro workshop, o primeiro passo na área de análise de dados é importar as informações nas quais você irá trabalhar, seja para um freela, estágio ou iniciação científica. Porém, existem diversas formas de importar dados e diversos dados que conseguimos importar, como por exemplo, podemos importar dados a partir de links, arquivos, com estruturas diversas e etc.

Esta parte da importação de dados, é o primeiro passo do _Ciclo de Ciência de Dados_ descrito no livro "R for Data Science". Depois de trazer estes arquivos para dentro do ambiente do RStudio, devemos arrumá-los, isto é, verificar se suas estruras estão boas para serem trabalhadas. Este procedimento é chamado de __Data Wrangling__ (será tema do próximo workshop, fiquem ligados!) e é uma parte essencial, uma vez que as nossas perguntas muitas vezes são respondidas depois de manipularmos as bases de dados.

Mas antes de avançarmos, o que são dados?

<a id='dados'></a>

## Eu vejo dados em todos os lugares!

<img src="https://github.com/p4hUSP/workshops_2018.2/blob/master/imgs/w1_14.jpg" class="giphyembed" class="center">

O que são dados? Essa é uma pergunta bem dificíl de responder e talvez traga um discussão muito maior do que podemos imaginar. Para esse workshop, uma respota no [Quora](https://www.quora.com/What-is-data-1) para a mesma pergunta basta:

> Data is an abstraction of reality. Raw data is an observation, that  captures some elements of reality. Data can then be aggregated and analysed in a variety of ways.

Esses dados, quando coletados podem vir de diversas formas, porém se queremos analisá-los no R, ou outros softwares, na maioria das vezes teremos que transformar estas informações em tabelas.

Acontece que até mesmo as tabelas podem vir em diversos formatos, como por exemplo, `.txt`, `.sav`, `.csv` e etc; Como podemos importar estes tipos de arquivos no R? Para nossa felicidade, o R fornece algumas formas (que chamaremos de funções) para resolver os nossos problemas. Normalmente estas funções estão relacionadas com o que chamamos de pacotes, que nada mais são que um conjunto de ferramentas que possuem alguma ação, como por exemplo, "abrir arquivo csv", "filtar observação do banco de dados" e assim por diante.

Alguns exemplos de pacotes são os seguintes:

<img src="https://github.com/p4hUSP/workshops_2018.2/blob/master/imgs/w1_12.png" class="pacotes" class="center">

Para instalar um pacote no R, utilizamos uma função chamada `install.packages()`. Após instalar o pacote de interesse, você deve habilitá-lo no seu ambiente do R com a função `library()`. Vamos ao código!

```{r warning=FALSE, message=FALSE, eval = FALSE}
# Instalando o pacote beepr (repare que ele deve estar entre "")
install.packages("cowsay")
# Habilitando o pacote
library("cowsay")
# Utilizando o pacote
say(what = "Vamos importar dados!", by = "random")
```

Toda função tem o que chamamos de parâmetros, que são valores passados para trazer resultados especificos. No exemplo acima, a função `say` pede para escrevermos qual é o parametro "what" e o by. De forma intuitiva a função `say` só funcionará se nós dissermos o que falar ("what") e quem deve falar ("by").

Agora é a sua vez! Peça para o mestre Yoda falar "may the force be with you". **Dica**: Escreva o nome do Yoda em minusculo e não esqueça das aspas.

```{r eval=FALSE}
say(what = "", by = "")
```

Conseguiu entender? Ao longo do tutorial iremos utilizar mais funções para fixar o conteúdo!

<a id='importar1'></a>

## Como abrir arquivos TXT, CSV e Arquivos Delimitados?

Neste workshop e nos próximos iremos utilizar um pacote chamado `tidyverse`. Segundo o [site do pacote](https://www.tidyverse.org/packages/), o `tidyverse`

> is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.

Como ele é uma coleção de pacotes para ciência de dados, temos como utilizar funções que vão desde como importar um dado, até como fazer visualizações e muito mais!

Dentro da área de importar dados, sobretudo, os tabulares, o `tidyverse` oferece a oportunidade de trabalharmos com os seguintes pacotes e suas funções:

- `readr`: Para importar arquivos que possuem delimitadores (.csv e .txt)

- `readxl`: Para importar arquivos do Excel (.xls e .xlsx)

- `haven`: Para importar dados de arquivos, como por exemplo, SPSS e Stata

Vamos lá!

```{r eval = FALSE}
library(tidyverse)
```

```{r eval = FALSE}
# CSV
w1_01 <- read_csv("/home/nathan/Documentos/Trabalho/P4H/workshops_2018.2/data/w1_01.csv")

# Delimitados
w1_02 <- read_delim("/home/nathan/Documentos/Trabalho/P4H/workshops_2018.2/data/w1_02.csv", delim = "@")
```

<a id='importar2'></a>

## Como abrir dados do Excel, SPSS e Stata?

```{r eval = FALSE}
# Excel
w1_06 <- read_xlsx("/home/nathan/Documentos/Trabalho/P4H/workshops_2018.2/data/w1_06.xlsx")

# STATA
w1_04 <- read_dta("/home/nathan/Documentos/Trabalho/P4H/workshops_2018.2/data/w1_04.dta")

# SPSS
w1_05 <- read_sav("/home/nathan/Documentos/Trabalho/P4H/workshops_2018.2/data/w1_05.sav")
```

Pronto! É assim que se importam dados para o R, muito fácil, não? Vamos para um desafio maior!

Uma das principais diferenças entre o Excel e o R (linguagens de programação em geral) é que o primeiro te mantem preso a uma lógica de como as coisas devem funcionar, enquanto o segundo te permite criar diversas soluções. Um exemplo disso, é o webScraping, que nada mais é que uma forma de extrair dados de sites utilizando códigos.

<a id='webscraping'></a>

## Importar dados utilizando Webscraping.

Partindo também para um definição mais "formal" da técnica, 

> "Web Scraping [...], can be defined as 'the construction of an agent to download, parse, and organize data from the web in an automated manner.' Or, in other words: instead of a human end user clicking away in a web browser and copy-pasting interesting parts into, say, a spreadsheet, web scraping offloads this task to a computer program that can execute it much faster, and more correctly, than a human can." (Practical Web Scraping for Data Science. BROUCKE & BAESENS, 2018).

O objetivo deste workshop é que possamos aprender como: fazer o download de páginas web, montar seus parsers e organizar os dados, que neste caso terão como resultado final uma tabela. Especificando um pouco mais nosso aprendizado, como maior parte das páginas web são construídas utilizando uma linguagem de marcação chamada HTML (Hypertext Markup Language), aprenderemos como extrair informações deste tipo de arquivo.

Vamos ver o que é esse tal arquivo HTML! Abra o `exemplo.html` na pasta `data` e com ele aberto clique com o botão direito em "Inspect". Ao clicar conseguimos ver o HTML dá página. Legal né? É desse tipo de arquivo que vamos extrair as informações que queremos.  

Vamos entender um pouco mais da estrutura do [HTML](https://www.youtube.com/watch?v=UjCbXQ8Coic)!

Ok! Mas como eu faço para extrair essas informações no R? Para fazer isso precisamos habilitar um pacote chamado `rvest`!

```{r eval = FALSE}
library(rvest)
```

O primeira passo é definir a url que iremos baixar/ler. Que tal fazer um scraper da área de política do [Jornal Nexo](https://www.nexojornal.com.br/tags/Temas/Pol%C3%ADtica)?

```{r eval = FALSE}
u0 <- "https://www.nexojornal.com.br/tags/Temas/Política"
```

Depois disso vamos ler o HTML da url

```{r eval = FALSE}
node <- read_html(u0)
```

Como será que é esse arquivo? E que classe ele percente?

```{r eval = FALSE}
node
```

```{r eval = FALSE}
class(node)
```

Ops! não vimos nada sobre classes aqui, isso é um problema? Não! Não precisa se preocupar, mas é importante entende a que classe pertence o objeto `node`. Ele pertence a duas classes que possuem em comum o termo "xml...", mas o que é isso? Nós não estamos interessados no HTML? 

Acontece que HTML pode ser considerado uma implementação do XML, eles poderiam ser considerados primos! Se você sabe um, você sabe o outro.

Vejamos este exemplo [aqui](https://pt.wikipedia.org/wiki/XML)!

Interessante, não? Mas como coletamos as informações? A resposta é simples, com `Xpath`.

> "XPath is a language used for locating nodes in XML documents." (Practical Web Scraping for Data Science. BROUCKE & BAESENS, 2018).

Basicamente, o `Xpath` é uma forma de informar onde uma determinada tag (ou um conjunto delas) está. Ficara mais claro quado colocarmos a mão na massa, mas por enquanto vamos nos familizarizar com algumas expressões do Xpath:


- "/" selects from the root node;

- "//" can be used to skip multiple levels of nodes and search through all descendants to perform a selection;

- "@" selects attributes.

Por incrível que pareça, conseguimos fazer muitas com essas expressões (é sério). Vamos ver alguns exemplos:

```{r eval = FALSE}
html_nodes(node, xpath = '/html/body/div')
```

```{r eval = FALSE}
html_nodes(node, xpath = '//div')
```

```{r eval = FALSE}
html_nodes(node, xpath = '/html/body//div')
```

```{r eval = FALSE}
html_nodes(node, xpath = '//div[@class="meta"]')
```

Podemos finalmente continuar o nosso WebScraping. Vamos escrever os "parsers", que basicamente são os códigos daquilo que queremos extrair do HTML. No caso do nexo nós queremos as seguintes informações:

<img src="https://github.com/p4hUSP/workshops_2018.2/blob/master/imgs/w1_15.png" class="center"> 

```{r eval = FALSE}
# Titulo das noticias
titulo <- html_nodes(node, xpath = '//div[@class="col-sm-3 col-sm-3"]//h3[@class="title "]')
titulo <- html_text(titulo)

# Classe da materia
classe <- html_nodes(node, xpath = '//div[@class="col-sm-3 col-sm-3"]//div[@class="kicker "]/a')
classe <- html_text(classe)

# Autor 
autor <- html_nodes(node, xpath = '//div[@class="meta"]/p[@class="author "]')
autor <- html_text(autor)

# Perceberam que o tamanho do vetor é menor?
## Talvez tenhamos que mudar de tag
autor <- html_nodes(node, xpath = '//div[@class="meta"]|span[@class="author "]')
autor <- html_text(autor)
```

Por fim, só precisamos organizar os dados em um data frame (Tabela)

```{r eval = FALSE}
# Colocando tudo em ma planilha
nexo <- data.frame(titulo = titulo, classe = classe, autor = autor, link = link)
```

Legal, não? Construímos a nosso próprio banco de dados! 

### Sua vez!

Tente fazer o mesmo com a área de [Economia do Nexo](https://www.nexojornal.com.br/tags/Temas/Economia)!

```{r eval = FALSE}
u0 <- "https://www.nexojornal.com.br/tags/Temas/Economia"
```

<a id='salvar'></a>  

## Salvando arquivos.

Depois que nós importamos os dados e darmos continuidado ao ciclo da Ciência de Dados, podemos salvá-los para, por exemplo, não precisar refazer todas mudanças já feitas. E é muito simples fazer isso, basta que utilizamos o prefixo `write_`, seguido da tabela que queremos salvar e o nome do arquivo que ela será salva (obs: não pode esquecer da extensão do arquivo, por exemplo ".csv"):

```{r eval = FALSE}
write_csv(nexo, "tabela_nexo.csv")
```

É isso! No próximo workshop veremos como manipular as bases de dados afim de ter uma informação consistente para qualquer análise, o que vai nos permitir também a chegar no terceiro workshop e produzir gráficos como este:

<img src="https://github.com/p4hUSP/workshops_2018.2/blob/master/imgs/graficos/w1_08.png" class="center"> 